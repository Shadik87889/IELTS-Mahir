<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AI Speaking Partner - Conversation Simulator</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <style>
      body {
        font-family: "Inter", sans-serif;
        background-color: #0c0d12;
        color: #e2e8f0;
        position: relative;
        overflow: hidden;
        display: flex;
        flex-direction: column;
        min-height: 100vh;
      }

      body::before {
        content: "";
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background-image: radial-gradient(
            circle at 25% 25%,
            rgba(99, 102, 241, 0.2) 0%,
            transparent 50%
          ),
          radial-gradient(
            circle at 75% 75%,
            rgba(59, 130, 246, 0.2) 0%,
            transparent 50%
          );
        z-index: -1;
      }

      .chat-container {
        flex-grow: 1;
        overflow-y: auto;
        padding: 1.5rem;
        display: flex;
        flex-direction: column;
      }

      .chat-bubble {
        max-width: 75%;
        padding: 0.75rem 1.25rem;
        border-radius: 1.25rem;
        margin-bottom: 1rem;
        position: relative;
        opacity: 0;
        transform: translateY(20px);
        animation: pop-in 0.4s forwards cubic-bezier(0.68, -0.55, 0.27, 1.55);
        display: flex;
        align-items: center;
        gap: 0.75rem;
      }

      @keyframes pop-in {
        to {
          opacity: 1;
          transform: translateY(0);
        }
      }

      .user-bubble {
        background: linear-gradient(135deg, #4a5568, #2d3748);
        color: white;
        align-self: flex-end;
        border-bottom-right-radius: 0.5rem;
      }

      .ai-bubble {
        background-color: #1e293b;
        color: #e2e8f0;
        align-self: flex-start;
        border-bottom-left-radius: 0.5rem;
      }

      .avatar {
        width: 32px;
        height: 32px;
        border-radius: 50%;
        flex-shrink: 0;
        background: linear-gradient(135deg, #4f46e5, #7c3aed);
        display: flex;
        align-items: center;
        justify-content: center;
      }

      .ai-bubble.speaking .avatar {
        animation: speaking-pulse 1.5s infinite;
      }

      @keyframes speaking-pulse {
        0% {
          box-shadow: 0 0 0 0 rgba(129, 140, 248, 0.7);
        }
        70% {
          box-shadow: 0 0 0 10px rgba(129, 140, 248, 0);
        }
        100% {
          box-shadow: 0 0 0 0 rgba(129, 140, 248, 0);
        }
      }

      .typing-indicator {
        display: flex;
        align-items: center;
        justify-content: center;
        padding: 0.5rem 0;
      }
      .typing-indicator span {
        height: 8px;
        width: 8px;
        background-color: #94a3b8;
        border-radius: 50%;
        margin: 0 3px;
        animation: bounce 1.4s infinite ease-in-out both;
      }
      .typing-indicator span:nth-of-type(1) {
        animation-delay: -0.32s;
      }
      .typing-indicator span:nth-of-type(2) {
        animation-delay: -0.16s;
      }
      @keyframes bounce {
        0%,
        80%,
        100% {
          transform: scale(0);
        }
        40% {
          transform: scale(1);
        }
      }

      .mic-button-container {
        position: fixed;
        bottom: 2rem;
        left: 50%;
        transform: translateX(-50%);
        z-index: 100;
      }

      .mic-button {
        width: 80px;
        height: 80px;
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        cursor: pointer;
        transition: all 0.3s ease;
        position: relative;
        background: #6366f1; /* Default to active color */
        box-shadow: 0 0 15px rgba(99, 102, 241, 0.6);
      }

      .mic-button:hover {
        background: #4f46e5;
      }

      .mic-button.listening::before {
        content: "";
        position: absolute;
        inset: -10px;
        border: 2px solid #6366f1;
        border-radius: 50%;
        animation: wave 1.5s infinite;
        opacity: 0;
      }

      @keyframes wave {
        0% {
          transform: scale(0.8);
          opacity: 0.5;
        }
        100% {
          transform: scale(1.5);
          opacity: 0;
        }
      }

      .status-text {
        position: fixed;
        bottom: 8rem;
        left: 50%;
        transform: translateX(-50%);
        background-color: rgba(30, 41, 59, 0.8);
        backdrop-filter: blur(5px);
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 9999px;
        font-size: 0.875rem;
        opacity: 0;
        transition: opacity 0.3s ease-in-out, transform 0.3s ease-in-out;
        pointer-events: none;
        transform: translateY(10px) translateX(-50%);
      }

      .status-text.visible {
        opacity: 1;
        transform: translateY(0) translateX(-50%);
      }
    </style>
  </head>
  <body>
    <div class="container mx-auto max-w-4xl flex flex-col h-screen">
      <!-- Welcome Screen -->
      <div
        id="welcome-screen"
        class="flex flex-col items-center justify-center h-full text-center px-4"
      >
        <div class="avatar mb-6 w-24 h-24">
          <svg
            class="w-12 h-12 text-white"
            fill="none"
            stroke="currentColor"
            viewBox="0 0 24 24"
            xmlns="http://www.w3.org/2000/svg"
          >
            <path
              stroke-linecap="round"
              stroke-linejoin="round"
              stroke-width="1.5"
              d="M8 12h.01M12 12h.01M16 12h.01M21 12c0 5.523-4.477 10-10 10S1 17.523 1 12 5.477 2 11 2s10 4.477 10 10z"
            ></path>
          </svg>
        </div>
        <h1 class="text-5xl font-extrabold text-white">AI Speaking Partner</h1>
        <p class="text-gray-400 mt-4 text-xl max-w-2xl">
          Choose a mode to start your real-time conversation practice.
        </p>
        <div class="flex flex-col sm:flex-row gap-4 mt-10">
          <button
            onclick="setConversationMode('friendly')"
            class="bg-indigo-600 hover:bg-indigo-700 text-white font-bold py-3 px-8 rounded-xl transition-all duration-300 transform hover:scale-105"
          >
            Friendly Chat
          </button>
          <button
            onclick="setConversationMode('ielts')"
            class="bg-gray-700 hover:bg-gray-600 text-white font-bold py-3 px-8 rounded-xl transition-all duration-300 transform hover:scale-105"
          >
            IELTS Practice
          </button>
        </div>
      </div>

      <!-- Chat View (Initially hidden) -->
      <div id="chat-view" class="hidden flex flex-col h-full">
        <header class="text-center py-6 border-b border-gray-800">
          <h1 id="header-title" class="text-2xl font-bold text-white">
            Conversation
          </h1>
        </header>
        <div id="chat-container" class="chat-container">
          <!-- Chat bubbles will be appended here -->
        </div>
      </div>

      <!-- Mic Button and Status (Global) -->
      <div class="mic-button-container">
        <div id="status-text" class="status-text">Listening...</div>
        <button id="mic-button" class="mic-button">
          <svg
            id="mic-icon"
            class="w-10 h-10 text-white"
            fill="none"
            stroke="currentColor"
            viewBox="0 0 24 24"
            xmlns="http://www.w3.org/2000/svg"
          >
            <path
              stroke-linecap="round"
              stroke-linejoin="round"
              stroke-width="2"
              d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"
            ></path>
          </svg>
        </button>
      </div>
    </div>

    <script>
      const micButton = document.getElementById("mic-button");
      const statusText = document.getElementById("status-text");
      const chatContainer = document.getElementById("chat-container");
      const headerTitle = document.getElementById("header-title");

      const SpeechRecognition =
        window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SpeechRecognition) {
        document.body.innerHTML =
          '<div class="text-center p-8">Sorry, your browser doesn\'t support the Speech Recognition API. Please use Chrome or Edge.</div>';
      }
      const recognition = new SpeechRecognition();
      recognition.continuous = false;
      recognition.lang = "en-US";
      recognition.interimResults = false;

      let isListening = false;
      let conversationHistory = [];
      let currentAudio = null;

      const friendlySystemPrompt = `You are an advanced AI English speaking partner designed to simulate a natural, friendly, and engaging conversation. Your name is 'AI Mahir'.
        - Your primary goal is to be a curious and warm conversation partner.
        - Start with a simple greeting and ask for the user's name.
        - Ask open-ended questions to encourage the user to speak more. Topics can range from hobbies, work, travel, technology, to culture.
        - Keep your responses concise, typically 1-3 sentences, to maintain a conversational pace.
        - Never correct the user's grammar. Act as a human conversation partner, not a robot.`;

      const ieltsSystemPrompt = `You are an AI English examiner simulating an IELTS speaking test. Your name is 'AI Mahir'.
        - Your tone should be professional, polite, and neutral, like a real examiner.
        - Start the test by asking for the user's full name.
        - Follow the structure of the IELTS speaking test: start with Part 1 (general questions), then introduce a Part 2 cue card topic, and finally ask Part 3 follow-up questions.
        - Transition between parts clearly. For example say: "Now, I'm going to give you a topic..."
        - Keep your questions direct and relevant to the test format. Do not engage in casual chat.`;

      function setConversationMode(mode) {
        const systemPromptText =
          mode === "ielts" ? ieltsSystemPrompt : friendlySystemPrompt;
        headerTitle.textContent =
          mode === "ielts"
            ? "IELTS Speaking Practice"
            : "Friendly Conversation";
        conversationHistory = [
          { role: "system", parts: [{ text: systemPromptText }] },
        ];

        document.getElementById("welcome-screen").classList.add("hidden");
        document.getElementById("chat-view").classList.remove("hidden");

        const firstMessage =
          mode === "ielts"
            ? "Hello, welcome to this simulated IELTS speaking test. My name is AI Mahir. Could you please tell me your full name?"
            : "Hello! I'm your AI speaking partner, AI Mahir. Let's have a chat! What's your name?";

        chatContainer.innerHTML = "";
        const initialBubble = addBubble(firstMessage, "ai");
        speak(firstMessage, initialBubble);
      }

      micButton.addEventListener("click", () => {
        if (currentAudio && !currentAudio.paused) currentAudio.pause();
        if (speechSynthesis.speaking) speechSynthesis.cancel();
        if (isListening) recognition.stop();
        else recognition.start();
      });

      recognition.onstart = () => {
        isListening = true;
        micButton.classList.add("listening");
        statusText.textContent = "Listening...";
        statusText.classList.add("visible");
      };
      recognition.onend = () => {
        isListening = false;
        micButton.classList.remove("listening");
        statusText.classList.remove("visible");
      };
      recognition.onerror = (e) => {
        console.error("Speech recognition error:", e.error);
        statusText.textContent = `Error: ${e.error}`;
        setTimeout(() => statusText.classList.remove("visible"), 3000);
      };
      recognition.onresult = (e) => {
        const transcript = e.results[0][0].transcript;
        addBubble(transcript, "user");
        getAIResponse(transcript);
      };

      function addBubble(text, role) {
        const bubble = document.createElement("div");
        bubble.classList.add(
          "chat-bubble",
          role === "user" ? "user-bubble" : "ai-bubble"
        );

        if (role === "ai") {
          const avatar = `<div class="avatar"><svg class="w-6 h-6 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M8 12h.01M12 12h.01M16 12h.01M21 12c0 5.523-4.477 10-10 10S1 17.523 1 12 5.477 2 11 2s10 4.477 10 10z"></path></svg></div>`;
          bubble.innerHTML = `${avatar} <p class="flex-grow">${text}</p>`;
        } else {
          bubble.textContent = text;
        }

        chatContainer.appendChild(bubble);
        chatContainer.scrollTop = chatContainer.scrollHeight;
        return bubble;
      }

      function addThinkingBubble() {
        const bubble = document.createElement("div");
        bubble.classList.add("chat-bubble", "ai-bubble");
        const avatar = `<div class="avatar"><svg class="w-6 h-6 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M8 12h.01M12 12h.01M16 12h.01M21 12c0 5.523-4.477 10-10 10S1 17.523 1 12 5.477 2 11 2s10 4.477 10 10z"></path></svg></div>`;
        const indicator = `<div class="typing-indicator"><span></span><span></span><span></span></div>`;
        bubble.innerHTML = avatar + indicator;
        chatContainer.appendChild(bubble);
        chatContainer.scrollTop = chatContainer.scrollHeight;
        return bubble;
      }

      async function fetchWithRetry(
        url,
        options,
        retries = 5,
        initialDelay = 1000
      ) {
        let delay = initialDelay;
        for (let i = 0; i < retries; i++) {
          try {
            const response = await fetch(url, options);
            if (response.status === 429) {
              // Exponential backoff for rate limiting
              await new Promise((resolve) => setTimeout(resolve, delay));
              delay *= 2;
              continue; // Retry the request
            }
            return response; // Success
          } catch (error) {
            if (i === retries - 1) throw error; // Rethrow on the last attempt
            await new Promise((resolve) => setTimeout(resolve, delay));
            delay *= 2;
          }
        }
        throw new Error("API request failed after multiple retries.");
      }

      async function getAIResponse(userText) {
        const thinkingBubble = addThinkingBubble();
        conversationHistory.push({ role: "user", parts: [{ text: userText }] });

        const payload = {
          contents: conversationHistory.map((item) => ({
            role: item.role === "system" ? "user" : item.role,
            parts: item.parts,
          })),
          systemInstruction: {
            parts: [{ text: conversationHistory[0].parts[0].text }],
          },
        };

        const apiKey = "AIzaSyCsdeFOJrU43BZmnRP5WD1pm80fZH1cxN4"; // API Key will be injected by the environment
        const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent?key=${apiKey}`;

        try {
          const response = await fetchWithRetry(apiUrl, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify(payload),
          });
          if (!response.ok) throw new Error(`API Error: ${response.status}`);
          const result = await response.json();
          const aiText = result.candidates[0].content.parts[0].text;

          conversationHistory.push({
            role: "model",
            parts: [{ text: aiText }],
          });
          // Pass control to speak function to synchronize text and audio
          await speak(aiText, thinkingBubble);
        } catch (error) {
          console.error("Error calling Gemini API:", error);
          const errText =
            "Sorry, I had a little trouble thinking. Could you say that again?";
          // Update the thinking bubble with an error message
          thinkingBubble.querySelector(".typing-indicator").remove();
          thinkingBubble
            .querySelector(".avatar")
            .insertAdjacentHTML(
              "afterend",
              `<p class="flex-grow">${errText}</p>`
            );
          await speak(errText, thinkingBubble, true); // Pass true to indicate it's an error message
        }
      }

      async function speak(text, bubbleElement, isError = false) {
        // If it's an existing bubble (like the initial message), don't modify it.
        const isThinkingBubble = bubbleElement.querySelector(
          ".typing-indicator"
        );

        // If it's an error message and we fail to get audio, just show the text.
        if (isError) {
          if (isThinkingBubble) {
            bubbleElement.querySelector(".typing-indicator").remove();
            bubbleElement
              .querySelector(".avatar")
              .insertAdjacentHTML(
                "afterend",
                `<p class="flex-grow">${text}</p>`
              );
          }
          return;
        }

        try {
          const payload = {
            contents: [{ parts: [{ text }] }],
            generationConfig: {
              responseModalities: ["AUDIO"],
              speechConfig: {
                voiceConfig: { prebuiltVoiceConfig: { voiceName: "Puck" } },
              },
            },
            model: "gemini-2.5-flash-preview-tts",
          };
          const apiKey = "AIzaSyCsdeFOJrU43BZmnRP5WD1pm80fZH1cxN4"; // API Key will be injected by the environment
          const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${apiKey}`;

          const response = await fetchWithRetry(apiUrl, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify(payload),
          });
          if (!response.ok)
            throw new Error(`TTS API Error: ${response.status}`);

          const result = await response.json();
          const audioData =
            result?.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
          const mimeType =
            result?.candidates?.[0]?.content?.parts?.[0]?.inlineData?.mimeType;

          if (audioData && mimeType?.startsWith("audio/")) {
            if (isThinkingBubble) {
              bubbleElement.querySelector(".typing-indicator").remove();
              bubbleElement
                .querySelector(".avatar")
                .insertAdjacentHTML(
                  "afterend",
                  `<p class="flex-grow">${text}</p>`
                );
            }

            const sampleRate = parseInt(mimeType.match(/rate=(\d+)/)[1], 10);
            const pcmData = base64ToArrayBuffer(audioData);
            const pcm16 = new Int16Array(pcmData);
            const wavBlob = pcmToWav(pcm16, 1, sampleRate);
            const audioUrl = URL.createObjectURL(wavBlob);

            bubbleElement.classList.add("speaking");
            currentAudio = new Audio(audioUrl);
            currentAudio.play();
            currentAudio.onended = () => {
              bubbleElement.classList.remove("speaking");
              // Automatically start listening for the user's response
              if (!isListening) setTimeout(() => recognition.start(), 300);
            };
          } else {
            throw new Error("Invalid audio data received.");
          }
        } catch (error) {
          console.error("Speech generation/playback error:", error);
          if (isThinkingBubble) {
            bubbleElement.querySelector(".typing-indicator").remove();
            bubbleElement
              .querySelector(".avatar")
              .insertAdjacentHTML(
                "afterend",
                `<p class="flex-grow">${text}</p>`
              );
          }
          bubbleElement.classList.remove("speaking");
        }
      }

      function base64ToArrayBuffer(base64) {
        const binaryString = window.atob(base64);
        const len = binaryString.length;
        const bytes = new Uint8Array(len);
        for (let i = 0; i < len; i++) bytes[i] = binaryString.charCodeAt(i);
        return bytes.buffer;
      }

      function pcmToWav(pcmData, numChannels, sampleRate) {
        const buffer = new ArrayBuffer(44 + pcmData.byteLength);
        const view = new DataView(buffer);
        const writeString = (offset, string) => {
          for (let i = 0; i < string.length; i++)
            view.setUint8(offset + i, string.charCodeAt(i));
        };

        writeString(0, "RIFF");
        view.setUint32(4, 36 + pcmData.byteLength, true);
        writeString(8, "WAVE");
        writeString(12, "fmt ");
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true);
        view.setUint16(22, numChannels, true);
        view.setUint32(24, sampleRate, true);
        view.setUint32(28, sampleRate * numChannels * 2, true);
        view.setUint16(32, numChannels * 2, true);
        view.setUint16(34, 16, true);
        writeString(36, "data");
        view.setUint32(40, pcmData.byteLength, true);
        new Int16Array(buffer, 44).set(pcmData);

        return new Blob([view], { type: "audio/wav" });
      }
    </script>
  </body>
</html>
