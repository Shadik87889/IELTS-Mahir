<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AI Speaking Partner - Conversation Simulator</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap"
      rel="stylesheet"
    />
    <style>
      body {
        font-family: "Inter", sans-serif;
        background-color: #0c0d12;
        color: #e2e8f0;
        position: relative;
        overflow: hidden;
        display: flex;
        flex-direction: column;
        min-height: 100vh;
      }

      /* Animated gradient background */
      body::before {
        content: "";
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background-image: radial-gradient(
            circle at 15% 25%,
            rgba(99, 102, 241, 0.25) 0%,
            transparent 40%
          ),
          radial-gradient(
            circle at 85% 75%,
            rgba(59, 130, 246, 0.2) 0%,
            transparent 40%
          );
        z-index: -1;
        animation: subtle-glow 15s infinite alternate;
      }

      @keyframes subtle-glow {
        0% {
          transform: scale(1);
        }
        100% {
          transform: scale(1.5);
        }
      }

      .chat-container {
        scrollbar-width: thin;
        scrollbar-color: #4a5568 #1e293b;
      }

      .chat-container::-webkit-scrollbar {
        width: 6px;
      }

      .chat-container::-webkit-scrollbar-track {
        background: #1e293b;
        border-radius: 10px;
      }

      .chat-container::-webkit-scrollbar-thumb {
        background-color: #4a5568;
        border-radius: 10px;
        border: 2px solid #1e293b;
      }

      .chat-bubble {
        max-width: 80%;
        padding: 0.85rem 1.25rem;
        border-radius: 1.25rem;
        margin-bottom: 1rem;
        position: relative;
        opacity: 0;
        transform: translateY(20px);
        animation: pop-in 0.4s forwards cubic-bezier(0.68, -0.55, 0.27, 1.55);
        display: flex;
        align-items: center;
        gap: 0.75rem;
        box-shadow: 0 4px 10px rgba(0, 0, 0, 0.2);
      }

      @keyframes pop-in {
        to {
          opacity: 1;
          transform: translateY(0);
        }
      }

      .user-bubble {
        background: linear-gradient(135deg, #4f46e5, #7c3aed);
        color: white;
        align-self: flex-end;
        border-bottom-right-radius: 0.5rem;
      }

      .ai-bubble {
        background-color: #1e293b;
        color: #e2e8f0;
        align-self: flex-start;
        border-bottom-left-radius: 0.5rem;
      }

      .avatar {
        width: 36px;
        height: 36px;
        border-radius: 50%;
        flex-shrink: 0;
        background: linear-gradient(135deg, #6366f1, #8b5cf6);
        display: flex;
        align-items: center;
        justify-content: center;
        box-shadow: 0 0 10px rgba(99, 102, 241, 0.5);
      }

      .ai-bubble.speaking .avatar {
        animation: speaking-pulse 1.5s infinite;
      }

      @keyframes speaking-pulse {
        0% {
          box-shadow: 0 0 0 0 rgba(129, 140, 248, 0.7);
        }
        70% {
          box-shadow: 0 0 0 10px rgba(129, 140, 248, 0);
        }
        100% {
          box-shadow: 0 0 0 0 rgba(129, 140, 248, 0);
        }
      }

      .typing-indicator span {
        height: 8px;
        width: 8px;
        background-color: #94a3b8;
        border-radius: 50%;
        margin: 0 3px;
        animation: bounce 1.4s infinite ease-in-out both;
      }
      .typing-indicator span:nth-of-type(1) {
        animation-delay: -0.32s;
      }
      .typing-indicator span:nth-of-type(2) {
        animation-delay: -0.16s;
      }
      @keyframes bounce {
        0%,
        80%,
        100% {
          transform: scale(0);
        }
        40% {
          transform: scale(1);
        }
      }

      .mic-button {
        width: 72px;
        height: 72px;
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        cursor: pointer;
        transition: all 0.3s ease;
        position: relative;
        background: #6366f1;
        box-shadow: 0 0 20px rgba(99, 102, 241, 0.6),
          0 4px 10px rgba(0, 0, 0, 0.3);
      }

      .mic-button:hover {
        background: #4f46e5;
        transform: scale(1.05);
      }

      .mic-button.listening::before {
        content: "";
        position: absolute;
        inset: -10px;
        border: 2px solid #6366f1;
        border-radius: 50%;
        animation: wave 1.5s infinite;
        opacity: 0;
      }

      @keyframes wave {
        0% {
          transform: scale(0.8);
          opacity: 0.5;
        }
        100% {
          transform: scale(1.5);
          opacity: 0;
        }
      }

      .glass-effect {
        background-color: rgba(12, 13, 18, 0.6);
        backdrop-filter: blur(10px);
        border-color: rgba(255, 255, 255, 0.1);
      }
    </style>
  </head>
  <body>
    <div class="container mx-auto max-w-4xl flex flex-col h-screen p-4">
      <!-- Welcome Screen -->
      <div
        id="welcome-screen"
        class="flex flex-col items-center justify-center h-full text-center px-4 transition-opacity duration-500"
      >
        <div class="avatar mb-6 w-24 h-24">
          <svg
            class="w-12 h-12 text-white"
            fill="none"
            stroke="currentColor"
            viewBox="0 0 24 24"
            xmlns="http://www.w3.org/2000/svg"
          >
            <path
              stroke-linecap="round"
              stroke-linejoin="round"
              stroke-width="1.5"
              d="M8 12h.01M12 12h.01M16 12h.01M21 12c0 5.523-4.477 10-10 10S1 17.523 1 12 5.477 2 11 2s10 4.477 10 10z"
            ></path>
          </svg>
        </div>
        <h1 class="text-5xl font-extrabold text-white tracking-tight">
          AI Speaking Partner
        </h1>
        <p class="text-gray-400 mt-4 text-xl max-w-2xl">
          Choose a mode to start your real-time conversation practice.
        </p>
        <div class="flex flex-col sm:flex-row gap-4 mt-12">
          <button
            onclick="setConversationMode('friendly')"
            class="bg-indigo-600 hover:bg-indigo-700 text-white font-bold py-4 px-8 rounded-xl transition-all duration-300 transform hover:scale-105 shadow-lg shadow-indigo-600/30"
          >
            Friendly Chat
          </button>
          <button
            onclick="setConversationMode('ielts')"
            class="bg-gray-700 hover:bg-gray-600 text-white font-bold py-4 px-8 rounded-xl transition-all duration-300 transform hover:scale-105 shadow-lg shadow-gray-700/30"
          >
            IELTS Practice
          </button>
        </div>
      </div>

      <!-- Chat View (Initially hidden) -->
      <div
        id="chat-view"
        class="hidden flex flex-col h-full transition-opacity duration-500"
      >
        <!-- Header -->
        <header
          class="text-center py-4 border-b glass-effect rounded-t-2xl flex justify-between items-center px-6"
        >
          <h1 id="header-title" class="text-xl font-bold text-white">
            Conversation
          </h1>
          <button
            id="end-session-btn"
            class="text-sm text-gray-400 hover:text-white transition-colors"
          >
            End Session
          </button>
        </header>

        <!-- Chat Container -->
        <div
          id="chat-container"
          class="chat-container flex flex-col flex-grow overflow-y-auto p-6 bg-black bg-opacity-20"
        >
          <!-- Chat bubbles will be appended here -->
        </div>

        <!-- Footer / Input Area -->
        <footer
          class="py-4 border-t glass-effect rounded-b-2xl flex flex-col items-center justify-center"
        >
          <div
            id="status-text"
            class="text-sm text-gray-400 h-5 mb-2 transition-opacity duration-300 opacity-0"
          >
            Listening...
          </div>
          <button id="mic-button" class="mic-button">
            <svg
              id="mic-icon"
              class="w-9 h-9 text-white"
              fill="currentColor"
              viewBox="0 0 24 24"
              xmlns="http://www.w3.org/2000/svg"
            >
              <path
                d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm5.3-3c0 3-2.54 5.1-5.3 5.1S6.7 14 6.7 11H5c0 3.41 2.72 6.23 6 6.72V21h2v-3.28c3.28-.49 6-3.31 6-6.72h-1.7z"
              ></path>
            </svg>
          </button>
        </footer>
      </div>
    </div>

    <script>
      const welcomeScreen = document.getElementById("welcome-screen");
      const chatView = document.getElementById("chat-view");
      const micButton = document.getElementById("mic-button");
      const statusText = document.getElementById("status-text");
      const chatContainer = document.getElementById("chat-container");
      const headerTitle = document.getElementById("header-title");
      const endSessionBtn = document.getElementById("end-session-btn");

      const SpeechRecognition =
        window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SpeechRecognition) {
        document.body.innerHTML =
          '<div class="text-center p-8">Sorry, your browser doesn\'t support the Speech Recognition API. Please use Chrome or Edge.</div>';
      }
      const recognition = new SpeechRecognition();
      recognition.continuous = false;
      recognition.lang = "en-US";
      recognition.interimResults = false;

      let isListening = false;
      let conversationHistory = [];
      let currentAudio = null;
      let isAiSpeaking = false;

      const friendlySystemPrompt = `You are an advanced AI English speaking partner designed to simulate a natural, friendly, and engaging conversation. Your name is 'AI Mahir'.
        - Your primary goal is to be a curious and warm conversation partner.
        - Start with a simple greeting and ask for the user's name.
        - Ask open-ended questions to encourage the user to speak more. Topics can range from hobbies, work, travel, technology, to culture.
        - Keep your responses concise, typically 1-3 sentences, to maintain a conversational pace.
        - Never correct the user's grammar. Act as a human conversation partner, not a robot.`;

      const ieltsSystemPrompt = `You are an AI English examiner simulating an IELTS speaking test. Your name is 'AI Mahir'.
        - Your tone should be professional, polite, and neutral, like a real examiner.
        - Start the test by asking for the user's full name.
        - Follow the structure of the IELTS speaking test: start with Part 1 (general questions), then introduce a Part 2 cue card topic, and finally ask Part 3 follow-up questions.
        - Transition between parts clearly. For example say: "Now, I'm going to give you a topic..."
        - Keep your questions direct and relevant to the test format. Do not engage in casual chat.`;

      function showScreen(screenName) {
        welcomeScreen.classList.add("opacity-0", "hidden");
        chatView.classList.add("opacity-0", "hidden");

        if (screenName === "welcome") {
          welcomeScreen.classList.remove("hidden");
          setTimeout(() => welcomeScreen.classList.remove("opacity-0"), 50);
        } else if (screenName === "chat") {
          chatView.classList.remove("hidden");
          setTimeout(() => chatView.classList.remove("opacity-0"), 50);
        }
      }

      function setConversationMode(mode) {
        const systemPromptText =
          mode === "ielts" ? ieltsSystemPrompt : friendlySystemPrompt;
        headerTitle.textContent =
          mode === "ielts"
            ? "IELTS Speaking Practice"
            : "Friendly Conversation";
        conversationHistory = [
          { role: "system", parts: [{ text: systemPromptText }] },
        ];

        showScreen("chat");

        const firstMessage =
          mode === "ielts"
            ? "Hello, welcome to this simulated IELTS speaking test. My name is AI Mahir. Could you please tell me your full name?"
            : "Hello! I'm your AI speaking partner, AI Mahir. Let's have a chat! What's your name?";

        chatContainer.innerHTML = "";
        const initialBubble = addBubble(firstMessage, "ai");
        speak(firstMessage, initialBubble);
      }

      endSessionBtn.addEventListener("click", () => {
        if (currentAudio) currentAudio.pause();
        if (speechSynthesis.speaking) speechSynthesis.cancel();
        if (isListening) recognition.stop();
        showScreen("welcome");
      });

      micButton.addEventListener("click", () => {
        if (isAiSpeaking) {
          if (currentAudio) currentAudio.pause();
          if (speechSynthesis.speaking) speechSynthesis.cancel();
          isAiSpeaking = false;
        }
        if (isListening) recognition.stop();
        else recognition.start();
      });

      recognition.onstart = () => {
        isListening = true;
        micButton.classList.add("listening");
        statusText.textContent = "Listening...";
        statusText.classList.remove("opacity-0");
      };
      recognition.onend = () => {
        isListening = false;
        micButton.classList.remove("listening");
        statusText.classList.add("opacity-0");
      };
      recognition.onerror = (e) => {
        console.error("Speech recognition error:", e.error);
        statusText.textContent = `Error: ${e.error}`;
        setTimeout(() => statusText.classList.add("opacity-0"), 3000);
      };
      recognition.onresult = (e) => {
        const transcript = e.results[0][0].transcript;
        addBubble(transcript, "user");
        getAIResponse(transcript);
      };

      function addBubble(text, role) {
        const bubble = document.createElement("div");
        bubble.classList.add(
          "chat-bubble",
          role === "user" ? "user-bubble" : "ai-bubble"
        );

        if (role === "ai") {
          const avatar = `<div class="avatar"><svg class="w-6 h-6 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M8 12h.01M12 12h.01M16 12h.01M21 12c0 5.523-4.477 10-10 10S1 17.523 1 12 5.477 2 11 2s10 4.477 10 10z"></path></svg></div>`;
          bubble.innerHTML = `${avatar} <p class="flex-grow">${text}</p>`;
        } else {
          bubble.innerHTML = `<p>${text}</p>`;
        }

        chatContainer.appendChild(bubble);
        chatContainer.scrollTop = chatContainer.scrollHeight;
        return bubble;
      }

      function addThinkingBubble() {
        const bubble = document.createElement("div");
        bubble.classList.add("chat-bubble", "ai-bubble");
        const avatar = `<div class="avatar"><svg class="w-6 h-6 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M8 12h.01M12 12h.01M16 12h.01M21 12c0 5.523-4.477 10-10 10S1 17.523 1 12 5.477 2 11 2s10 4.477 10 10z"></path></svg></div>`;
        const indicator = `<div class="typing-indicator flex-grow flex items-center"><span></span><span></span><span></span></div>`;
        bubble.innerHTML = avatar + indicator;
        chatContainer.appendChild(bubble);
        chatContainer.scrollTop = chatContainer.scrollHeight;
        return bubble;
      }

      async function fetchWithRetry(
        url,
        options,
        retries = 5,
        initialDelay = 1000
      ) {
        let delay = initialDelay;
        for (let i = 0; i < retries; i++) {
          try {
            const response = await fetch(url, options);
            if (response.status === 429) {
              await new Promise((resolve) => setTimeout(resolve, delay));
              delay *= 2;
              continue;
            }
            return response;
          } catch (error) {
            if (i === retries - 1) throw error;
            await new Promise((resolve) => setTimeout(resolve, delay));
            delay *= 2;
          }
        }
        throw new Error("API request failed after multiple retries.");
      }

      async function getAIResponse(userText) {
        const thinkingBubble = addThinkingBubble();
        conversationHistory.push({ role: "user", parts: [{ text: userText }] });

        // Ensure we only include the system prompt once, implicitly
        const payloadContents = conversationHistory.slice(1).map((item) => ({
          role: item.role === "model" ? "model" : "user", // Gemini uses 'model' for AI
          parts: item.parts,
        }));

        const payload = {
          contents: payloadContents,
          systemInstruction: conversationHistory[0],
        };

        const apiKey = "AIzaSyCsdeFOJrU43BZmnRP5WD1pm80fZH1cxN4"; // API Key will be injected by the environment
        const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent?key=${apiKey}`;

        try {
          const response = await fetchWithRetry(apiUrl, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify(payload),
          });
          if (!response.ok) throw new Error(`API Error: ${response.status}`);
          const result = await response.json();
          const aiText = result.candidates[0].content.parts[0].text;

          conversationHistory.push({
            role: "model",
            parts: [{ text: aiText }],
          });
          await speak(aiText, thinkingBubble);
        } catch (error) {
          console.error("Error calling Gemini API:", error);
          const errText =
            "Sorry, I had a little trouble thinking. Could you say that again?";
          updateBubbleContent(thinkingBubble, errText);
          await speak(errText, thinkingBubble, true);
        }
      }

      function updateBubbleContent(bubbleElement, text) {
        const contentContainer = bubbleElement.querySelector(
          "p, .typing-indicator"
        );
        const newContent = document.createElement("p");
        newContent.className = "flex-grow";
        newContent.textContent = text;
        if (contentContainer) {
          contentContainer.replaceWith(newContent);
        } else {
          bubbleElement
            .querySelector(".avatar")
            .insertAdjacentElement("afterend", newContent);
        }
      }

      async function speak(text, bubbleElement, isError = false) {
        isAiSpeaking = true;

        if (isError) {
          updateBubbleContent(bubbleElement, text);
          isAiSpeaking = false;
          return;
        }

        try {
          const payload = {
            contents: [{ parts: [{ text }] }],
            generationConfig: {
              responseModalities: ["AUDIO"],
              speechConfig: {
                voiceConfig: { prebuiltVoiceConfig: { voiceName: "Puck" } },
              },
            },
            model: "gemini-2.5-flash-preview-tts",
          };
          const apiKey = "AIzaSyCsdeFOJrU43BZmnRP5WD1pm80fZH1cxN4"; // API Key will be injected by the environment
          const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${apiKey}`;

          const response = await fetchWithRetry(apiUrl, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify(payload),
          });
          if (!response.ok)
            throw new Error(`TTS API Error: ${response.status}`);

          const result = await response.json();
          const audioData =
            result?.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
          const mimeType =
            result?.candidates?.[0]?.content?.parts?.[0]?.inlineData?.mimeType;

          if (audioData && mimeType?.startsWith("audio/")) {
            updateBubbleContent(bubbleElement, text);

            const sampleRate = parseInt(mimeType.match(/rate=(\d+)/)[1], 10);
            const pcmData = base64ToArrayBuffer(audioData);
            const pcm16 = new Int16Array(pcmData);
            const wavBlob = pcmToWav(pcm16, 1, sampleRate);
            const audioUrl = URL.createObjectURL(wavBlob);

            bubbleElement.classList.add("speaking");
            currentAudio = new Audio(audioUrl);
            currentAudio.play();
            currentAudio.onended = () => {
              isAiSpeaking = false;
              bubbleElement.classList.remove("speaking");
              if (!isListening) setTimeout(() => recognition.start(), 300);
            };
          } else {
            throw new Error("Invalid audio data received.");
          }
        } catch (error) {
          console.error("Speech generation/playback error:", error);
          updateBubbleContent(bubbleElement, text); // Fallback to text-only
          bubbleElement.classList.remove("speaking");
          isAiSpeaking = false;
        }
      }

      function base64ToArrayBuffer(base64) {
        const binaryString = window.atob(base64);
        const len = binaryString.length;
        const bytes = new Uint8Array(len);
        for (let i = 0; i < len; i++) bytes[i] = binaryString.charCodeAt(i);
        return bytes.buffer;
      }

      function pcmToWav(pcmData, numChannels, sampleRate) {
        const buffer = new ArrayBuffer(44 + pcmData.byteLength);
        const view = new DataView(buffer);
        const writeString = (offset, string) => {
          for (let i = 0; i < string.length; i++)
            view.setUint8(offset + i, string.charCodeAt(i));
        };

        writeString(0, "RIFF");
        view.setUint32(4, 36 + pcmData.byteLength, true);
        writeString(8, "WAVE");
        writeString(12, "fmt ");
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true);
        view.setUint16(22, numChannels, true);
        view.setUint32(24, sampleRate, true);
        view.setUint32(28, sampleRate * numChannels * 2, true);
        view.setUint16(32, numChannels * 2, true);
        view.setUint16(34, 16, true);
        writeString(36, "data");
        view.setUint32(40, pcmData.byteLength, true);
        new Int16Array(buffer, 44).set(pcmData);

        return new Blob([view], { type: "audio/wav" });
      }

      // Initial load
      showScreen("welcome");
    </script>
  </body>
</html>
