<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AI Speaking Partner - Conversation Simulator</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <style>
      body {
        font-family: "Inter", sans-serif;
        background-color: #0c0d12;
        color: #e2e8f0;
        position: relative;
        overflow: hidden;
        display: flex;
        flex-direction: column;
        min-height: 100vh;
      }

      body::before {
        content: "";
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background-image: radial-gradient(
            circle at 25% 25%,
            rgba(99, 102, 241, 0.2) 0%,
            transparent 50%
          ),
          radial-gradient(
            circle at 75% 75%,
            rgba(59, 130, 246, 0.2) 0%,
            transparent 50%
          );
        z-index: -1;
      }

      .chat-container {
        flex-grow: 1;
        overflow-y: auto;
        padding: 1.5rem;
        display: flex;
        flex-direction: column;
      }

      .chat-bubble {
        max-width: 75%;
        padding: 0.75rem 1.25rem;
        border-radius: 1.25rem;
        margin-bottom: 1rem;
        position: relative;
        opacity: 0;
        transform: translateY(20px);
        animation: pop-in 0.4s forwards cubic-bezier(0.68, -0.55, 0.27, 1.55);
        display: flex;
        align-items: center;
        gap: 0.75rem;
      }

      @keyframes pop-in {
        to {
          opacity: 1;
          transform: translateY(0);
        }
      }

      .user-bubble {
        background: linear-gradient(135deg, #4a5568, #2d3748);
        color: white;
        align-self: flex-end;
        border-bottom-right-radius: 0.5rem;
      }

      .ai-bubble {
        background-color: #1e293b;
        color: #e2e8f0;
        align-self: flex-start;
        border-bottom-left-radius: 0.5rem;
      }

      .avatar {
        width: 32px;
        height: 32px;
        border-radius: 50%;
        flex-shrink: 0;
        background: linear-gradient(135deg, #4f46e5, #7c3aed);
        display: flex;
        align-items: center;
        justify-content: center;
      }

      .ai-bubble.speaking .avatar {
        animation: speaking-pulse 1.5s infinite;
      }

      @keyframes speaking-pulse {
        0% {
          box-shadow: 0 0 0 0 rgba(129, 140, 248, 0.7);
        }
        70% {
          box-shadow: 0 0 0 10px rgba(129, 140, 248, 0);
        }
        100% {
          box-shadow: 0 0 0 0 rgba(129, 140, 248, 0);
        }
      }

      .typing-indicator {
        display: flex;
        align-items: center;
        justify-content: center;
        padding: 0.5rem 0;
      }
      .typing-indicator span {
        height: 8px;
        width: 8px;
        background-color: #94a3b8;
        border-radius: 50%;
        margin: 0 3px;
        animation: bounce 1.4s infinite ease-in-out both;
      }
      .typing-indicator span:nth-of-type(1) {
        animation-delay: -0.32s;
      }
      .typing-indicator span:nth-of-type(2) {
        animation-delay: -0.16s;
      }
      @keyframes bounce {
        0%,
        80%,
        100% {
          transform: scale(0);
        }
        40% {
          transform: scale(1);
        }
      }

      .mic-button-container {
        position: fixed;
        bottom: 2rem;
        left: 50%;
        transform: translateX(-50%);
        z-index: 100;
      }

      .mic-button {
        width: 80px;
        height: 80px;
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        cursor: pointer;
        transition: all 0.3s ease;
        position: relative;
      }

      .mic-button.listening::before {
        content: "";
        position: absolute;
        inset: -10px;
        border: 2px solid #6366f1;
        border-radius: 50%;
        animation: wave 1.5s infinite;
        opacity: 0;
      }

      @keyframes wave {
        0% {
          transform: scale(0.8);
          opacity: 0.5;
        }
        100% {
          transform: scale(1.5);
          opacity: 0;
        }
      }

      .status-text {
        position: fixed;
        bottom: 8rem;
        left: 50%;
        transform: translateX(-50%);
        background-color: rgba(30, 41, 59, 0.8);
        backdrop-filter: blur(5px);
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 9999px;
        font-size: 0.875rem;
        opacity: 0;
        transition: opacity 0.3s ease-in-out, transform 0.3s ease-in-out;
        pointer-events: none;
        transform: translateY(10px) translateX(-50%);
      }

      .status-text.visible {
        opacity: 1;
        transform: translateY(0) translateX(-50%);
      }
    </style>
  </head>
  <body>
    <div class="container mx-auto max-w-4xl flex flex-col h-screen">
      <!-- Welcome Screen -->
      <div
        id="welcome-screen"
        class="flex flex-col items-center justify-center h-full text-center px-4"
      >
        <div class="avatar mb-6 w-24 h-24">
          <svg
            class="w-12 h-12 text-white"
            fill="none"
            stroke="currentColor"
            viewBox="0 0 24 24"
            xmlns="http://www.w3.org/2000/svg"
          >
            <path
              stroke-linecap="round"
              stroke-linejoin="round"
              stroke-width="1.5"
              d="M8 12h.01M12 12h.01M16 12h.01M21 12c0 5.523-4.477 10-10 10S1 17.523 1 12 5.477 2 11 2s10 4.477 10 10z"
            ></path>
          </svg>
        </div>
        <h1 class="text-5xl font-extrabold text-white">AI Speaking Partner</h1>
        <p class="text-gray-400 mt-4 text-xl max-w-2xl">
          Choose a mode to start your real-time conversation practice.
        </p>
        <div class="flex flex-col sm:flex-row gap-4 mt-10">
          <button
            onclick="setConversationMode('friendly')"
            class="bg-indigo-600 hover:bg-indigo-700 text-white font-bold py-3 px-8 rounded-xl transition-all duration-300 transform hover:scale-105"
          >
            Friendly Chat
          </button>
          <button
            onclick="setConversationMode('ielts')"
            class="bg-gray-700 hover:bg-gray-600 text-white font-bold py-3 px-8 rounded-xl transition-all duration-300 transform hover:scale-105"
          >
            IELTS Practice
          </button>
        </div>
      </div>

      <!-- Chat View (Initially hidden) -->
      <div id="chat-view" class="hidden flex flex-col h-full">
        <header class="text-center py-6 border-b border-gray-800">
          <h1 id="header-title" class="text-2xl font-bold text-white">
            Conversation
          </h1>
        </header>
        <div id="chat-container" class="chat-container">
          <!-- Chat bubbles will be appended here -->
        </div>
      </div>

      <!-- Mic Button and Status (Global) -->
      <div class="mic-button-container">
        <div id="status-text" class="status-text">Listening...</div>
        <button
          id="mic-button"
          class="mic-button bg-indigo-600 hover:bg-indigo-700"
        >
          <svg
            id="mic-icon"
            class="w-10 h-10 text-white"
            fill="none"
            stroke="currentColor"
            viewBox="0 0 24 24"
            xmlns="http://www.w3.org/2000/svg"
          >
            <path
              stroke-linecap="round"
              stroke-linejoin="round"
              stroke-width="2"
              d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"
            ></path>
          </svg>
        </button>
      </div>
    </div>

    <script>
      const micButton = document.getElementById("mic-button");
      const statusText = document.getElementById("status-text");
      const chatContainer = document.getElementById("chat-container");
      const headerTitle = document.getElementById("header-title");

      const SpeechRecognition =
        window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SpeechRecognition) {
        document.body.innerHTML =
          '<div class="text-center p-8">Sorry, your browser doesn\'t support the Speech Recognition API. Please use Chrome or Edge.</div>';
      }
      const recognition = new SpeechRecognition();
      recognition.continuous = false;
      recognition.lang = "en-US";
      recognition.interimResults = false;

      let isListening = false;
      let conversationHistory = [];

      const friendlySystemPrompt = `You are an advanced AI English speaking partner designed to simulate a natural, friendly, and engaging conversation. Your name is 'Gem'.
        - Your primary goal is to be a curious and warm conversation partner.
        - Start with a simple greeting and ask for the user's name.
        - Ask open-ended questions to encourage the user to speak more. Topics can range from hobbies, work, travel, technology, to culture.
        - Keep your responses concise, typically 1-3 sentences, to maintain a conversational pace.
        - Never correct the user's grammar. Act as a human conversation partner, not a robot.`;

      const ieltsSystemPrompt = `You are an AI English examiner simulating an IELTS speaking test. Your name is 'Gem'.
        - Your tone should be professional, polite, and neutral, like a real examiner.
        - Start the test by asking for the user's full name.
        - Follow the structure of the IELTS speaking test: start with Part 1 (general questions), then introduce a Part 2 cue card topic, and finally ask Part 3 follow-up questions.
        - Transition between parts clearly. For example say: "Now, I'm going to give you a topic..."
        - Keep your questions direct and relevant to the test format. Do not engage in casual chat.`;

      function setConversationMode(mode) {
        const systemPromptText =
          mode === "ielts" ? ieltsSystemPrompt : friendlySystemPrompt;
        headerTitle.textContent =
          mode === "ielts"
            ? "IELTS Speaking Practice"
            : "Friendly Conversation";
        conversationHistory = [
          { role: "system", parts: [{ text: systemPromptText }] },
        ];

        document.getElementById("welcome-screen").classList.add("hidden");
        document.getElementById("chat-view").classList.remove("hidden");

        const firstMessage =
          mode === "ielts"
            ? "Hello, welcome to this simulated IELTS speaking test. My name is Gem. Could you please tell me your full name?"
            : "Hello! I'm your AI speaking partner, Gem. Let's have a chat! What's your name?";

        chatContainer.innerHTML = "";
        const initialBubble = addBubble(firstMessage, "ai");
        speak(firstMessage, initialBubble);
      }

      micButton.addEventListener("click", () => {
        if (speechSynthesis.speaking) speechSynthesis.cancel();
        if (isListening) recognition.stop();
        else recognition.start();
      });

      recognition.onstart = () => {
        isListening = true;
        micButton.classList.add("listening");
        statusText.textContent = "Listening...";
        statusText.classList.add("visible");
      };
      recognition.onend = () => {
        isListening = false;
        micButton.classList.remove("listening");
        statusText.classList.remove("visible");
      };
      recognition.onerror = (e) => {
        console.error("Speech recognition error:", e.error);
        statusText.textContent = `Error: ${e.error}`;
        setTimeout(() => statusText.classList.remove("visible"), 3000);
      };
      recognition.onresult = (e) => {
        const transcript = e.results[0][0].transcript;
        addBubble(transcript, "user");
        getAIResponse(transcript);
      };

      function addBubble(text, role) {
        const bubble = document.createElement("div");
        bubble.classList.add(
          "chat-bubble",
          role === "user" ? "user-bubble" : "ai-bubble"
        );

        if (role === "ai") {
          const avatar = `<div class="avatar"><svg class="w-6 h-6 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M8 12h.01M12 12h.01M16 12h.01M21 12c0 5.523-4.477 10-10 10S1 17.523 1 12 5.477 2 11 2s10 4.477 10 10z"></path></svg></div>`;
          bubble.innerHTML = `${avatar} <p class="flex-grow">${text}</p>`;
        } else {
          bubble.textContent = text;
        }

        chatContainer.appendChild(bubble);
        chatContainer.scrollTop = chatContainer.scrollHeight;
        return bubble;
      }

      function addThinkingBubble() {
        const bubble = document.createElement("div");
        bubble.classList.add("chat-bubble", "ai-bubble");
        const avatar = `<div class="avatar"><svg class="w-6 h-6 text-white" fill="none" stroke="currentColor" viewBox="0 0 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M8 12h.01M12 12h.01M16 12h.01M21 12c0 5.523-4.477 10-10 10S1 17.523 1 12 5.477 2 11 2s10 4.477 10 10z"></path></svg></div>`;
        const indicator = `<div class="typing-indicator"><span></span><span></span><span></span></div>`;
        bubble.innerHTML = avatar + indicator;
        chatContainer.appendChild(bubble);
        chatContainer.scrollTop = chatContainer.scrollHeight;
        return bubble;
      }

      async function getAIResponse(userText) {
        const thinkingBubble = addThinkingBubble();
        conversationHistory.push({ role: "user", parts: [{ text: userText }] });

        const payload = {
          contents: conversationHistory.map((item) => ({
            role: item.role === "system" ? "user" : item.role,
            parts: item.parts,
          })),
          systemInstruction: {
            parts: [{ text: conversationHistory[0].parts[0].text }],
          },
        };

        const apiKey = "AIzaSyCsdeFOJrU43BZmnRP5WD1pm80fZH1cxN4";
        const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent?key=${apiKey}`;

        try {
          const response = await fetch(apiUrl, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify(payload),
          });
          if (!response.ok) throw new Error(`API Error: ${response.status}`);
          const result = await response.json();
          const aiText = result.candidates[0].content.parts[0].text;

          thinkingBubble.querySelector(".typing-indicator").remove();
          thinkingBubble
            .querySelector(".avatar")
            .insertAdjacentHTML(
              "afterend",
              `<p class="flex-grow">${aiText}</p>`
            );

          conversationHistory.push({
            role: "model",
            parts: [{ text: aiText }],
          });
          await speak(aiText, thinkingBubble);
        } catch (error) {
          console.error("Error calling Gemini API:", error);
          const errText =
            "Sorry, I had a little trouble thinking. Could you say that again?";
          thinkingBubble.querySelector(".typing-indicator").remove();
          thinkingBubble
            .querySelector(".avatar")
            .insertAdjacentHTML(
              "afterend",
              `<p class="flex-grow">${errText}</p>`
            );
          await speak(errText, thinkingBubble);
        }
      }

      async function speak(text, bubbleElement) {
        try {
          const payload = {
            contents: [{ parts: [{ text }] }],
            generationConfig: {
              responseModalities: ["AUDIO"],
              speechConfig: {
                voiceConfig: { prebuiltVoiceConfig: { voiceName: "Puck" } },
              },
            },
            model: "gemini-2.5-flash-preview-tts",
          };
          const apiKey = "AIzaSyCsdeFOJrU43BZmnRP5WD1pm80fZH1cxN4";
          const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${apiKey}`;

          const response = await fetch(apiUrl, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify(payload),
          });
          if (!response.ok)
            throw new Error(`TTS API Error: ${response.status}`);

          const result = await response.json();
          const audioData =
            result?.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
          const mimeType =
            result?.candidates?.[0]?.content?.parts?.[0]?.inlineData?.mimeType;

          if (audioData && mimeType?.startsWith("audio/")) {
            const sampleRate = parseInt(mimeType.match(/rate=(\d+)/)[1], 10);
            const pcmData = base64ToArrayBuffer(audioData);
            const pcm16 = new Int16Array(pcmData);
            const wavBlob = pcmToWav(pcm16, 1, sampleRate);
            const audioUrl = URL.createObjectURL(wavBlob);

            bubbleElement.classList.add("speaking");
            const audio = new Audio(audioUrl);
            audio.play();
            audio.onended = () => {
              bubbleElement.classList.remove("speaking");
              if (!isListening) setTimeout(() => micButton.click(), 300);
            };
          } else {
            throw new Error("Invalid audio data received.");
          }
        } catch (error) {
          console.error("Speech generation/playback error:", error);
          bubbleElement.classList.remove("speaking");
        }
      }

      function base64ToArrayBuffer(base64) {
        const binaryString = window.atob(base64);
        const len = binaryString.length;
        const bytes = new Uint8Array(len);
        for (let i = 0; i < len; i++) bytes[i] = binaryString.charCodeAt(i);
        return bytes.buffer;
      }

      function pcmToWav(pcmData, numChannels, sampleRate) {
        const buffer = new ArrayBuffer(44 + pcmData.byteLength);
        const view = new DataView(buffer);
        const writeString = (offset, string) => {
          for (let i = 0; i < string.length; i++)
            view.setUint8(offset + i, string.charCodeAt(i));
        };

        writeString(0, "RIFF");
        view.setUint32(4, 36 + pcmData.byteLength, true);
        writeString(8, "WAVE");
        writeString(12, "fmt ");
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true);
        view.setUint16(22, numChannels, true);
        view.setUint32(24, sampleRate, true);
        view.setUint32(28, sampleRate * numChannels * 2, true);
        view.setUint16(32, numChannels * 2, true);
        view.setUint16(34, 16, true);
        writeString(36, "data");
        view.setUint32(40, pcmData.byteLength, true);
        new Int16Array(buffer, 44).set(pcmData);

        return new Blob([view], { type: "audio/wav" });
      }
    </script>
  </body>
</html>

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AI Speaking Partner - Conversation Simulator</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap"
      rel="stylesheet"
    />
    <style>
      :root {
        --bg-color: #0a090f;
        --primary-glow: rgba(99, 102, 241, 0.5);
        --secondary-glow: rgba(59, 130, 246, 0.5);
        --primary-accent: #6366f1;
        --secondary-accent: #3b82f6;
        --text-primary: #f8fafc;
        --text-secondary: #94a3b8;
        --surface-color: #1e293b;
      }

      body {
        font-family: "Inter", sans-serif;
        background-color: var(--bg-color);
        color: var(--text-primary);
        position: relative;
        overflow: hidden;
        display: flex;
        flex-direction: column;
        min-height: 100vh;
      }

      /* Aurora background effect */
      body::before {
        content: "";
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background-image: radial-gradient(
            ellipse 50% 50% at 20% 25%,
            var(--primary-glow),
            transparent 70%
          ),
          radial-gradient(
            ellipse 50% 50% at 80% 75%,
            var(--secondary-glow),
            transparent 70%
          );
        z-index: -1;
        animation: subtle-pulse 15s infinite alternate;
      }

      @keyframes subtle-pulse {
        from {
          opacity: 0.8;
        }
        to {
          opacity: 1;
        }
      }

      .chat-container {
        flex-grow: 1;
        overflow-y: auto;
        padding: 1.5rem;
        display: flex;
        flex-direction: column;
        scrollbar-width: thin;
        scrollbar-color: var(--primary-accent) transparent;
      }

      .chat-container::-webkit-scrollbar {
        width: 6px;
      }
      .chat-container::-webkit-scrollbar-track {
        background: transparent;
      }
      .chat-container::-webkit-scrollbar-thumb {
        background-color: var(--primary-accent);
        border-radius: 20px;
      }

      .chat-bubble {
        max-width: 75%;
        padding: 0.75rem 1.25rem;
        border-radius: 1.25rem;
        margin-bottom: 1rem;
        position: relative;
        opacity: 0;
        transform: translateY(20px);
        animation: pop-in 0.5s forwards cubic-bezier(0.68, -0.55, 0.27, 1.55);
        display: flex;
        align-items: center;
        gap: 0.75rem;
        border: 1px solid rgba(255, 255, 255, 0.05);
      }

      @keyframes pop-in {
        to {
          opacity: 1;
          transform: translateY(0);
        }
      }

      .user-bubble {
        background: linear-gradient(135deg, #4f46e5, #7c3aed);
        color: white;
        align-self: flex-end;
        border-bottom-right-radius: 0.5rem;
        box-shadow: 0 4px 15px rgba(124, 58, 237, 0.2);
      }

      .ai-bubble {
        background-color: rgba(30, 41, 59, 0.8);
        backdrop-filter: blur(10px);
        color: var(--text-primary);
        align-self: flex-start;
        border-bottom-left-radius: 0.5rem;
      }

      .avatar {
        width: 36px;
        height: 36px;
        border-radius: 50%;
        flex-shrink: 0;
        background: linear-gradient(
          135deg,
          var(--primary-accent),
          var(--secondary-accent)
        );
        display: flex;
        align-items: center;
        justify-content: center;
        box-shadow: 0 0 10px var(--primary-glow);
      }

      .ai-bubble.speaking .avatar {
        animation: speaking-pulse 1.5s infinite;
      }

      @keyframes speaking-pulse {
        0% {
          box-shadow: 0 0 0 0 rgba(99, 102, 241, 0.7);
        }
        70% {
          box-shadow: 0 0 0 12px rgba(99, 102, 241, 0);
        }
        100% {
          box-shadow: 0 0 0 0 rgba(99, 102, 241, 0);
        }
      }

      .typing-indicator {
        display: flex;
        align-items: center;
        justify-content: center;
        padding: 0.5rem 0;
      }
      .typing-indicator span {
        height: 8px;
        width: 8px;
        background-color: var(--text-secondary);
        border-radius: 50%;
        margin: 0 3px;
        animation: bounce 1.4s infinite ease-in-out both;
      }
      .typing-indicator span:nth-of-type(1) {
        animation-delay: -0.32s;
      }
      .typing-indicator span:nth-of-type(2) {
        animation-delay: -0.16s;
      }
      @keyframes bounce {
        0%,
        80%,
        100% {
          transform: scale(0);
        }
        40% {
          transform: scale(1);
        }
      }

      .mic-button-container {
        position: fixed;
        bottom: 2.5rem;
        left: 50%;
        transform: translateX(-50%);
        z-index: 100;
        display: flex;
        flex-direction: column;
        align-items: center;
      }

      .mic-button {
        width: 80px;
        height: 80px;
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        cursor: pointer;
        transition: all 0.3s cubic-bezier(0.19, 1, 0.22, 1);
        position: relative;
        background: linear-gradient(
          145deg,
          var(--primary-accent),
          var(--secondary-accent)
        );
        box-shadow: 0 0 25px var(--primary-glow),
          inset 0 2px 5px rgba(255, 255, 255, 0.2);
        border: 2px solid rgba(255, 255, 255, 0.1);
      }

      .mic-button:hover {
        transform: scale(1.1);
        box-shadow: 0 0 40px var(--primary-glow),
          inset 0 2px 5px rgba(255, 255, 255, 0.2);
      }

      .mic-button.listening {
        animation: mic-pulse 1.5s infinite;
      }

      @keyframes mic-pulse {
        0% {
          transform: scale(1);
        }
        50% {
          transform: scale(1.1);
        }
        100% {
          transform: scale(1);
        }
      }

      .status-text {
        position: absolute;
        bottom: 110%; /* Position above the mic button */
        background-color: rgba(30, 41, 59, 0.9);
        backdrop-filter: blur(8px);
        color: white;
        padding: 0.5rem 1.25rem;
        border-radius: 9999px;
        font-size: 0.9rem;
        font-weight: 500;
        opacity: 0;
        transition: opacity 0.3s ease-in-out, transform 0.3s ease-in-out;
        pointer-events: none;
        transform: translateY(10px);
        border: 1px solid rgba(255, 255, 255, 0.1);
      }

      .status-text.visible {
        opacity: 1;
        transform: translateY(0);
      }

      /* Welcome Screen Specific Styles */
      #welcome-screen .main-avatar {
        background: linear-gradient(
          145deg,
          var(--primary-accent),
          var(--secondary-accent)
        );
        box-shadow: 0 0 40px var(--primary-glow);
        animation: float 6s ease-in-out infinite;
      }

      @keyframes float {
        0% {
          box-shadow: 0 0 40px var(--primary-glow);
          transform: translatey(0px);
        }
        50% {
          box-shadow: 0 0 50px var(--secondary-glow);
          transform: translatey(-20px);
        }
        100% {
          box-shadow: 0 0 40px var(--primary-glow);
          transform: translatey(0px);
        }
      }

      .mode-button {
        background-color: rgba(30, 41, 59, 0.7);
        backdrop-filter: blur(10px);
        border: 1px solid rgba(255, 255, 255, 0.1);
        color: var(--text-primary);
        font-weight: bold;
        padding: 0.75rem 2rem;
        border-radius: 0.75rem;
        transition: all 0.3s ease;
        position: relative;
        overflow: hidden;
      }
      .mode-button:before {
        content: "";
        position: absolute;
        top: 0;
        left: -100%;
        width: 100%;
        height: 100%;
        background: linear-gradient(
          120deg,
          transparent,
          rgba(255, 255, 255, 0.1),
          transparent
        );
        transition: all 0.5s;
      }

      .mode-button:hover {
        transform: translateY(-5px);
        box-shadow: 0 10px 20px rgba(0, 0, 0, 0.2);
      }
      .mode-button:hover:before {
        left: 100%;
      }
    </style>
  </head>
  <body>
    <div class="container mx-auto max-w-4xl flex flex-col h-screen">
      <!-- Welcome Screen -->
      <div
        id="welcome-screen"
        class="flex flex-col items-center justify-center h-full text-center px-4"
      >
        <div class="main-avatar avatar mb-8 w-28 h-28">
          <svg
            class="w-16 h-16 text-white"
            fill="none"
            stroke="currentColor"
            viewBox="0 0 24 24"
            xmlns="http://www.w3.org/2000/svg"
          >
            <path
              stroke-linecap="round"
              stroke-linejoin="round"
              stroke-width="1.5"
              d="M7 8h10M7 12h4m1 8l-4-4H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-3l-4 4z"
            ></path>
          </svg>
        </div>
        <h1
          class="text-5xl md:text-6xl font-extrabold text-white tracking-tight"
        >
          AI Speaking Partner
        </h1>
        <p class="text-gray-300 mt-4 text-lg md:text-xl max-w-2xl">
          Sharpen your English speaking skills with a friendly AI. Choose a mode
          to begin.
        </p>
        <div class="flex flex-col sm:flex-row gap-5 mt-12">
          <button onclick="setConversationMode('friendly')" class="mode-button">
            Friendly Chat
          </button>
          <button onclick="setConversationMode('ielts')" class="mode-button">
            IELTS Practice
          </button>
        </div>
      </div>

      <!-- Chat View (Initially hidden) -->
      <div id="chat-view" class="hidden flex flex-col h-full">
        <header
          class="text-center py-6 border-b border-gray-800/50 backdrop-blur-sm"
        >
          <h1 id="header-title" class="text-2xl font-bold text-white">
            Conversation
          </h1>
        </header>
        <div id="chat-container" class="chat-container">
          <!-- Chat bubbles will be appended here -->
        </div>
      </div>

      <!-- Mic Button and Status (Global) -->
      <div class="mic-button-container">
        <div id="status-text" class="status-text">Listening...</div>
        <button id="mic-button" class="mic-button">
          <svg
            id="mic-icon"
            class="w-10 h-10 text-white"
            fill="none"
            stroke="currentColor"
            viewBox="0 0 24 24"
            xmlns="http://www.w3.org/2000/svg"
          >
            <path
              stroke-linecap="round"
              stroke-linejoin="round"
              stroke-width="2"
              d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"
            ></path>
          </svg>
        </button>
      </div>
    </div>

    <script>
      const micButton = document.getElementById("mic-button");
      const statusText = document.getElementById("status-text");
      const chatContainer = document.getElementById("chat-container");
      const headerTitle = document.getElementById("header-title");
      const welcomeScreen = document.getElementById("welcome-screen");
      const chatView = document.getElementById("chat-view");

      const SpeechRecognition =
        window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SpeechRecognition) {
        document.body.innerHTML =
          '<div class="text-center p-8">Sorry, your browser doesn\'t support the Speech Recognition API. Please use Chrome or Edge.</div>';
      }
      const recognition = new SpeechRecognition();
      recognition.continuous = false;
      recognition.lang = "en-US";
      recognition.interimResults = false;

      let isListening = false;
      let conversationHistory = [];
      let currentAudio = null;

      const friendlySystemPrompt = `You are an advanced AI English speaking partner designed to simulate a natural, friendly, and engaging conversation. Your name is 'Zen'.
        - Your primary goal is to be a curious and warm conversation partner.
        - Start with a simple greeting and ask for the user's name.
        - Ask open-ended questions to encourage the user to speak more. Topics can range from hobbies, work, travel, technology, to culture.
        - Keep your responses concise, typically 1-3 sentences, to maintain a conversational pace.
        - Never correct the user's grammar. Act as a human conversation partner, not a robot.`;

      const ieltsSystemPrompt = `You are an AI English examiner simulating an IELTS speaking test. Your name is 'Zen'.
        - Your tone should be professional, polite, and neutral, like a real examiner.
        - Start the test by asking for the user's full name.
        - Follow the structure of the IELTS speaking test: start with Part 1 (general questions), then introduce a Part 2 cue card topic, and finally ask Part 3 follow-up questions.
        - Transition between parts clearly. For example say: "Now, I'm going to give you a topic..."
        - Keep your questions direct and relevant to the test format. Do not engage in casual chat.`;

      function setConversationMode(mode) {
        const systemPromptText =
          mode === "ielts" ? ieltsSystemPrompt : friendlySystemPrompt;
        headerTitle.textContent =
          mode === "ielts"
            ? "IELTS Speaking Practice"
            : "Friendly Conversation";
        conversationHistory = [
          { role: "system", parts: [{ text: systemPromptText }] },
        ];

        welcomeScreen.style.transition =
          "opacity 0.5s ease-out, transform 0.5s ease-out";
        welcomeScreen.style.opacity = "0";
        welcomeScreen.style.transform = "scale(0.95)";

        setTimeout(() => {
          welcomeScreen.classList.add("hidden");
          chatView.classList.remove("hidden");
          chatView.style.opacity = "0";
          chatView.style.transform = "scale(0.95)";
          setTimeout(() => {
            chatView.style.transition =
              "opacity 0.5s ease-in, transform 0.5s ease-in";
            chatView.style.opacity = "1";
            chatView.style.transform = "scale(1)";
          }, 50);
        }, 500);

        const firstMessage =
          mode === "ielts"
            ? "Hello, welcome to this simulated IELTS speaking test. My name is Zen. Could you please tell me your full name?"
            : "Hello! I'm your AI speaking partner, Zen. Let's have a chat! What's your name?";

        chatContainer.innerHTML = "";
        const initialBubble = addBubble(firstMessage, "ai");
        speak(firstMessage, initialBubble);
      }

      micButton.addEventListener("click", () => {
        if (currentAudio && !currentAudio.paused) currentAudio.pause();
        if (speechSynthesis.speaking) speechSynthesis.cancel();
        if (isListening) recognition.stop();
        else recognition.start();
      });

      recognition.onstart = () => {
        isListening = true;
        micButton.classList.add("listening");
        statusText.textContent = "Listening...";
        statusText.classList.add("visible");
      };
      recognition.onend = () => {
        isListening = false;
        micButton.classList.remove("listening");
        statusText.classList.remove("visible");
      };
      recognition.onerror = (e) => {
        console.error("Speech recognition error:", e.error);
        statusText.textContent = `Error: ${e.error}`;
        setTimeout(() => statusText.classList.remove("visible"), 3000);
      };
      recognition.onresult = (e) => {
        const transcript = e.results[0][0].transcript;
        addBubble(transcript, "user");
        getAIResponse(transcript);
      };

      function addBubble(text, role) {
        const bubble = document.createElement("div");
        bubble.classList.add(
          "chat-bubble",
          role === "user" ? "user-bubble" : "ai-bubble"
        );

        if (role === "ai") {
          const avatar = `<div class="avatar"><svg class="w-6 h-6 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M7 8h10M7 12h4m1 8l-4-4H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-3l-4 4z"></path></svg></div>`;
          bubble.innerHTML = `${avatar} <p class="flex-grow">${text}</p>`;
        } else {
          bubble.textContent = text;
        }

        chatContainer.appendChild(bubble);
        chatContainer.scrollTop = chatContainer.scrollHeight;
        return bubble;
      }

      function addThinkingBubble() {
        const bubble = document.createElement("div");
        bubble.classList.add("chat-bubble", "ai-bubble");
        const avatar = `<div class="avatar"><svg class="w-6 h-6 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M7 8h10M7 12h4m1 8l-4-4H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-3l-4 4z"></path></svg></div>`;
        const indicator = `<div class="typing-indicator"><span></span><span></span><span></span></div>`;
        bubble.innerHTML = avatar + indicator;
        chatContainer.appendChild(bubble);
        chatContainer.scrollTop = chatContainer.scrollHeight;
        return bubble;
      }

      async function fetchWithRetry(
        url,
        options,
        retries = 5,
        initialDelay = 1000
      ) {
        let delay = initialDelay;
        for (let i = 0; i < retries; i++) {
          try {
            const response = await fetch(url, options);
            if (response.status === 429) {
              // Exponential backoff for rate limiting
              await new Promise((resolve) => setTimeout(resolve, delay));
              delay *= 2;
              continue; // Retry the request
            }
            return response; // Success
          } catch (error) {
            if (i === retries - 1) throw error; // Rethrow on the last attempt
            await new Promise((resolve) => setTimeout(resolve, delay));
            delay *= 2;
          }
        }
        throw new Error("API request failed after multiple retries.");
      }

      async function getAIResponse(userText) {
        const thinkingBubble = addThinkingBubble();
        conversationHistory.push({ role: "user", parts: [{ text: userText }] });

        const payload = {
          contents: conversationHistory.map((item) => ({
            role: item.role === "system" ? "user" : item.role,
            parts: item.parts,
          })),
          systemInstruction: {
            parts: [{ text: conversationHistory[0].parts[0].text }],
          },
        };

        const apiKey = "AIzaSyCsdeFOJrU43BZmnRP5WD1pm80fZH1cxN4"; // API Key will be injected by the environment
        const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent?key=${apiKey}`;

        try {
          const response = await fetchWithRetry(apiUrl, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify(payload),
          });
          if (!response.ok) throw new Error(`API Error: ${response.status}`);
          const result = await response.json();
          const aiText = result.candidates[0].content.parts[0].text;

          conversationHistory.push({
            role: "model",
            parts: [{ text: aiText }],
          });
          await speak(aiText, thinkingBubble);
        } catch (error) {
          console.error("Error calling Gemini API:", error);
          const errText =
            "Sorry, I had a little trouble thinking. Could you say that again?";
          thinkingBubble.querySelector(".typing-indicator").remove();
          thinkingBubble
            .querySelector(".avatar")
            .insertAdjacentHTML(
              "afterend",
              `<p class="flex-grow">${errText}</p>`
            );
          await speak(errText, thinkingBubble, true);
        }
      }

      async function speak(text, bubbleElement, isError = false) {
        const isThinkingBubble = bubbleElement.querySelector(
          ".typing-indicator"
        );

        if (isThinkingBubble) {
          bubbleElement.querySelector(".typing-indicator").remove();
          bubbleElement
            .querySelector(".avatar")
            .insertAdjacentHTML("afterend", `<p class="flex-grow">${text}</p>`);
        }

        if (isError) {
          return;
        }

        try {
          const payload = {
            contents: [{ parts: [{ text }] }],
            generationConfig: {
              responseModalities: ["AUDIO"],
              speechConfig: {
                voiceConfig: { prebuiltVoiceConfig: { voiceName: "Puck" } },
              },
            },
            model: "gemini-2.5-flash-preview-tts",
          };
          const apiKey = "AIzaSyCsdeFOJrU43BZmnRP5WD1pm80fZH1cxN4"; // API Key will be injected by the environment
          const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${apiKey}`;

          const response = await fetchWithRetry(apiUrl, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify(payload),
          });
          if (!response.ok)
            throw new Error(`TTS API Error: ${response.status}`);

          const result = await response.json();
          const audioData =
            result?.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
          const mimeType =
            result?.candidates?.[0]?.content?.parts?.[0]?.inlineData?.mimeType;

          if (audioData && mimeType?.startsWith("audio/")) {
            const sampleRate = parseInt(mimeType.match(/rate=(\d+)/)[1], 10);
            const pcmData = base64ToArrayBuffer(audioData);
            const pcm16 = new Int16Array(pcmData);
            const wavBlob = pcmToWav(pcm16, 1, sampleRate);
            const audioUrl = URL.createObjectURL(wavBlob);

            bubbleElement.classList.add("speaking");
            currentAudio = new Audio(audioUrl);
            currentAudio.play();
            currentAudio.onended = () => {
              bubbleElement.classList.remove("speaking");
              if (!isListening) setTimeout(() => recognition.start(), 300);
            };
          } else {
            throw new Error("Invalid audio data received.");
          }
        } catch (error) {
          console.error("Speech generation/playback error:", error);
          bubbleElement.classList.remove("speaking");
        }
      }

      function base64ToArrayBuffer(base64) {
        const binaryString = window.atob(base64);
        const len = binaryString.length;
        const bytes = new Uint8Array(len);
        for (let i = 0; i < len; i++) bytes[i] = binaryString.charCodeAt(i);
        return bytes.buffer;
      }

      function pcmToWav(pcmData, numChannels, sampleRate) {
        const buffer = new ArrayBuffer(44 + pcmData.byteLength);
        const view = new DataView(buffer);
        const writeString = (offset, string) => {
          for (let i = 0; i < string.length; i++)
            view.setUint8(offset + i, string.charCodeAt(i));
        };

        writeString(0, "RIFF");
        view.setUint32(4, 36 + pcmData.byteLength, true);
        writeString(8, "WAVE");
        writeString(12, "fmt ");
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true);
        view.setUint16(22, numChannels, true);
        view.setUint32(24, sampleRate, true);
        view.setUint32(28, sampleRate * numChannels * 2, true);
        view.setUint16(32, numChannels * 2, true);
        view.setUint16(34, 16, true);
        writeString(36, "data");
        view.setUint32(40, pcmData.byteLength, true);
        new Int16Array(buffer, 44).set(pcmData);

        return new Blob([view], { type: "audio/wav" });
      }
    </script>
  </body>
</html>
